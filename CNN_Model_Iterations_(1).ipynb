{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import copy\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# ---------- Reproducibility ---------- #\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---------- Show sample images ---------- #\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hK1GtFeUpi-W"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- EarlyStopping Helper ---------- #\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, delta=0):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_acc):\n",
        "        score = val_acc\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n"
      ],
      "metadata": {
        "id": "N4iHyRKthwcs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup_data(x, y, alpha=0.2):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(x.device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "9siVZaJYydId"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Models ---------- #\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class ImprovedCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# ---------- Residual Block ---------- #\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=False):\n",
        "        super().__init__()\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(out_channels)\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.downsample = nn.Sequential()\n",
        "        if downsample or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.downsample(x)\n",
        "        out = self.block(x)\n",
        "        out += identity\n",
        "        return self.relu(out)\n",
        "\n",
        "# ---------- ResNet Style CNN ---------- #\n",
        "class ResNetStyleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.initial = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            ResidualBlock(64, 64),\n",
        "            ResidualBlock(64, 64)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            ResidualBlock(64, 128, downsample=True),\n",
        "            ResidualBlock(128, 128)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            ResidualBlock(128, 256, downsample=True),\n",
        "            ResidualBlock(256, 256)\n",
        "        )\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "EFMuyvaEpk4e"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Prepare CIFAR-10 ---------- #\n",
        "def prepare_data(batch_size=64):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),\n",
        "        transforms.ColorJitter(brightness = 0.2, contrast = 0.2, saturation = 0.2),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3)),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    full_trainset = torchvision.datasets.CIFAR10(root='.', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='.', train=False, download=True, transform=transform)\n",
        "    train_size = int(0.8 * len(full_trainset))\n",
        "    val_size = len(full_trainset) - train_size\n",
        "    trainset, valset = random_split(full_trainset, [train_size, val_size])\n",
        "    kwargs = {'num_workers': 2, 'pin_memory': torch.cuda.is_available()}\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, **kwargs)\n",
        "    return trainloader, valloader, testloader, full_trainset.classes\n",
        "\n",
        "# ---------- Train, Validate, Test ---------- #\n",
        "def train_evaluate(model, trainloader, valloader, testloader, device, name=\"Model\", epochs=5, use_mixup = True):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
        "    early_stopper = EarlyStopping(patience = 10, delta = 0.001)\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss, correct, total = 0.0, 0, 0\n",
        "        for x, y in trainloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            if use_mixup:\n",
        "                inputs, targets_a, targets_b, lam = mixup_data(x, y, alpha=0.2)\n",
        "                out = model(inputs)\n",
        "                loss = mixup_criterion(criterion, out, targets_a, targets_b, lam)\n",
        "            else:\n",
        "                out = model(x)\n",
        "                loss = criterion(out, y)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, pred = torch.max(out, 1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "        train_accs.append(100 * correct / total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss, correct, total = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in valloader:\n",
        "                x, y = x.to(device), y.to(device)\n",
        "                out = model(x)\n",
        "                val_loss += criterion(out, y).item()\n",
        "                _, pred = torch.max(out, 1)\n",
        "                correct += (pred == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        val_losses.append(val_loss / len(valloader))\n",
        "        val_acc = 100 * correct / total\n",
        "        val_accs.append(val_acc)\n",
        "        print(f\"[{name}] Epoch {epoch+1} - Train Acc: {train_accs[-1]:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save model if validation improves\n",
        "        if val_accs[-1] > best_val_acc:\n",
        "            best_val_acc = val_accs[-1]\n",
        "            torch.save(model.state_dict(), f\"{name}_best_model.pth\")\n",
        "\n",
        "        # Early stopping check\n",
        "        early_stopper(val_accs[-1])\n",
        "        if early_stopper.early_stop:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "\n",
        "    # Test\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in testloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            _, pred = torch.max(out, 1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "    print(f\"[{name}] Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs\n"
      ],
      "metadata": {
        "id": "VjU-iQ4cpk1W"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "def evaluate_model(model, dataloader, device, class_names):\n",
        "    model.eval()\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            out = model(x)\n",
        "            _, preds = torch.max(out, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_targets.extend(y.cpu().numpy())\n",
        "\n",
        "    print(\"\\nðŸ“Š Classification Report:\")\n",
        "    print(classification_report(all_targets, all_preds, target_names=class_names))\n",
        "\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    disp.plot(cmap=\"Blues\", xticks_rotation=45)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "agv8oZmH6qHL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(train_losses, val_losses, train_accs, val_accs, title=\"Model\"):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
        "    plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"{title} - Loss Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accs, label=\"Train Accuracy\")\n",
        "    plt.plot(epochs, val_accs, label=\"Val Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"{title} - Accuracy Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0WTX-9RC6zD3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_results(results):\n",
        "    print(\"\\n Summary of Final Validation Accuracies:\\n\")\n",
        "    for name, metrics in results.items():\n",
        "        print(f\"{name:20s} - Final Val Acc: {metrics['val_accs'][-1]:.2f}%\")"
      ],
      "metadata": {
        "id": "bYlJwujD-j40"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_best_model(model_class, path, device):\n",
        "    model = model_class().to(device)\n",
        "    model.load_state_dict(torch.load(path, map_location=device))\n",
        "    model.eval()\n",
        "    print(f\"Loaded best model from {path}\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "PJzndfqx6-v9"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_all_models(model_classes, epochs=5, use_mixup=True):\n",
        "    set_seed()\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    trainloader, valloader, testloader, classes = prepare_data()\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_class in model_classes:\n",
        "        name = model_class.__name__\n",
        "        print(f\"\\n Running model: {name}\\n\")\n",
        "        model = model_class()\n",
        "\n",
        "        train_losses, val_losses, train_accs, val_accs = train_evaluate(\n",
        "            model, trainloader, valloader, testloader, device, name, epochs, use_mixup=use_mixup\n",
        "        )\n",
        "\n",
        "        # Plot training curves\n",
        "        plot_curves(train_losses, val_losses, train_accs, val_accs, title=name)\n",
        "\n",
        "        # Load and evaluate best model\n",
        "        best_model = load_best_model(model_class, f\"{name}_best_model.pth\", device)\n",
        "        evaluate_model(best_model, testloader, device, classes)\n",
        "\n",
        "        results[name] = {\n",
        "            \"train_losses\": train_losses,\n",
        "            \"val_losses\": val_losses,\n",
        "            \"train_accs\": train_accs,\n",
        "            \"val_accs\": val_accs\n",
        "        }\n",
        "\n",
        "    summarize_results(results)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "KgJC0nMl-RNR"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == \"__main__\":\n",
        "#    run_all_models([SimpleCNN, ImprovedCNN, ResNetStyleCNN], epochs=40, use_mixup = False)"
      ],
      "metadata": {
        "id": "gdlRhcVWpkxn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    run_all_models([ResNetStyleCNN], epochs=40, use_mixup = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZEBebAzlXfd",
        "outputId": "f51ce9d1-c02f-4c84-b9a5-d4cf0f248666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Running model: ResNetStyleCNN\n",
            "\n",
            "[ResNetStyleCNN] Epoch 1 - Train Acc: 31.28% | Val Acc: 40.51%\n",
            "[ResNetStyleCNN] Epoch 2 - Train Acc: 48.81% | Val Acc: 55.16%\n"
          ]
        }
      ]
    }
  ]
}